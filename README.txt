##READ ME##

Please download the dataset in this Google Drive link: https://drive.google.com/drive/folders/1OrzxgQdsIWYRDI6mPN6HM6R4_xBJoEia?usp=share_link

The capstone_environment.txt file is the required environment package to be used when running the jupyter notebooks.


Access the jupyter notebooks with the following order:

1. Data Preparation and EDA
    - The aim of this notebook is to prepare the dataset that will be used for the project, as well as perform an exploratory data analysis of 
      the cleaned data.

2. Data Preprocessing for Baseline
    - The aim of this notebook is to preprocess the cleaned dataset to make it ready for modelling our baseline model.

3. Baseline Model
    - The aim of this notebook is to build our first model, a baseline model, using Logistic Regression.
    
4. Model Experimentation
    - In this notebook, we are expanding our baseline model and experimenting with other machine learning models in order to come up with the 
      best possible model.

5. Multiclass Classification Models
    - In this notebook, we will be making multiclass classification models that aims to predict which four shipment outcomes (classes) an 
      order item will fall onto: Late Delivery, Advanced Shipping, Shipping on Time, or Shipping Canceled.
    
6. Model Deployment Simulation
    - In this notebook, we will demonstrate how the machine learning model we created will be used in practice.

Inside the Dataset folder consists the original raw dataset and several other modified versions that are saved from the jupyter notebooks and are read back in another jupyter notebook from above.